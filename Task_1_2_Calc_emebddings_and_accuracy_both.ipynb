{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVAiArStTra8",
    "outputId": "dac16570-12a3-42bc-e634-6c07f90360c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zn1RV1qHTsIl",
    "outputId": "4efade4f-6fb3-4503-dd92-bcbe28cc72fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-ba8781aeeb4a>:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All eval data shape: (10, 2500, 32, 32, 3)\n",
      "All eval targets shape: (10, 2500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-ba8781aeeb4a>:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All eval data 2 shape: (10, 2500, 32, 32, 3)\n",
      "All eval targets 2 shape: (10, 2500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-ba8781aeeb4a>:89: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All train data shape: (10, 2500, 32, 32, 3)\n",
      "All train targets shape: (1, 2500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-ba8781aeeb4a>:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All train data 2 shape: (10, 2500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# List of paths to dataset files\n",
    "dataset_paths = [\n",
    "     '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/eval_data/7_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/eval_data/8_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/eval_data/9_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/eval_data/10_eval_data.tar.pth',\n",
    "]\n",
    "\n",
    "# Initialize lists to store data and targets from each dataset\n",
    "all_eval_data = []\n",
    "all_eval_targets = []\n",
    "\n",
    "# Loop through each dataset path and load the data and targets\n",
    "for path in dataset_paths:\n",
    "    dataset = torch.load(path)\n",
    "    data = dataset['data']\n",
    "    targets = dataset['targets']\n",
    "\n",
    "    # Append to the lists\n",
    "    all_eval_data.append(data)\n",
    "    all_eval_targets.append(targets)\n",
    "all_eval_data = np.array(all_eval_data)\n",
    "all_eval_targets = np.array(all_eval_targets)\n",
    "\n",
    "# Print the shape of the concatenated tensors to verify\n",
    "print(\"All eval data shape:\", all_eval_data.shape)\n",
    "print(\"All eval targets shape:\", all_eval_targets.shape)\n",
    "\n",
    "dataset_paths = [\n",
    "     '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/eval_data/1_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/eval_data/2_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/eval_data/3_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/eval_data/4_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/eval_data/5_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/eval_data/6_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/eval_data/7_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/eval_data/8_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/eval_data/9_eval_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/eval_data/10_eval_data.tar.pth',\n",
    "]\n",
    "\n",
    "# Initialize lists to store data and targets from each dataset\n",
    "all_eval_data_2 = []\n",
    "all_eval_targets_2 = []\n",
    "\n",
    "# Loop through each dataset path and load the data and targets\n",
    "for path in dataset_paths:\n",
    "    dataset = torch.load(path)\n",
    "    data = dataset['data']\n",
    "    targets = dataset['targets']\n",
    "\n",
    "    # Append to the lists\n",
    "    all_eval_data_2.append(data)\n",
    "    all_eval_targets_2.append(targets)\n",
    "all_eval_data_2 = np.array(all_eval_data_2)\n",
    "all_eval_targets_2 = np.array(all_eval_targets_2)\n",
    "\n",
    "# Print the shape of the concatenated tensors to verify\n",
    "print(\"All eval data 2 shape:\", all_eval_data_2.shape)\n",
    "print(\"All eval targets 2 shape:\", all_eval_targets_2.shape)\n",
    "\n",
    "dataset_paths = [\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/train_data/1_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/train_data/2_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/train_data/3_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/train_data/4_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/train_data/5_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/train_data/6_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/train_data/7_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/train_data/8_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/train_data/9_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_one_dataset/train_data/10_train_data.tar.pth',\n",
    "]\n",
    "\n",
    "# Initialize lists to store data and targets from each dataset\n",
    "all_train_data = []\n",
    "all_train_targets = []\n",
    "i=0\n",
    "# Loop through each dataset path and load the data and targets\n",
    "for path in dataset_paths:\n",
    "    dataset = torch.load(path)\n",
    "    data = dataset['data']\n",
    "    if i==0:\n",
    "      targets = dataset['targets']\n",
    "      i+=1\n",
    "      all_train_targets.append(targets)\n",
    "    # Append to the lists\n",
    "    all_train_data.append(data)\n",
    "\n",
    "all_train_data = np.array(all_train_data)\n",
    "all_train_targets = np.array(all_train_targets)\n",
    "\n",
    "# Print the shape of the concatenated tensors to verify\n",
    "print(\"All train data shape:\", all_train_data.shape)\n",
    "print(\"All train targets shape:\", all_train_targets.shape)\n",
    "\n",
    "dataset_paths = [\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/train_data/1_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/train_data/2_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/train_data/3_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/train_data/4_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/train_data/5_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/train_data/6_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/train_data/7_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/train_data/8_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/train_data/9_train_data.tar.pth',\n",
    "    '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/part_two_dataset/train_data/10_train_data.tar.pth',\n",
    "]\n",
    "\n",
    "# Initialize lists to store data and targets from each dataset\n",
    "all_train_data_2 = []\n",
    "all_train_targets_2 = []\n",
    "i=0\n",
    "# Loop through each dataset path and load the data and targets\n",
    "for path in dataset_paths:\n",
    "    dataset = torch.load(path)\n",
    "    data = dataset['data']\n",
    "\n",
    "    # Append to the lists\n",
    "    all_train_data_2.append(data)\n",
    "    #all_train_targets_2.append(targets)\n",
    "all_train_data_2 = np.array(all_train_data_2)\n",
    "\n",
    "\n",
    "# Print the shape of the concatenated tensors to verify\n",
    "print(\"All train data 2 shape:\", all_train_data_2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "47IqKuKTUSvM",
    "outputId": "4e9e9f40-04a3-43ca-8207-90ec2ac56280"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 173MB/s]\n",
      "<ipython-input-3-fb5249b53a96>:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained ResNet-50 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer to have 10 output classes\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "\n",
    "# Move the model to the GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Path to your trained model weights\n",
    "model_path = '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/dataset/resnet.pth'  # Correct the path if necessary\n",
    "\n",
    "# Load the trained weights and move the model to GPU\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qdUEsu2I6H0v"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import cv2\n",
    "\n",
    "# A function to enhance image based on different enhancement strategies\n",
    "def enhance_image(image_array, i):\n",
    "  if i == 0  :\n",
    "    return enhance_image_1(image_array)\n",
    "  if i == 1:\n",
    "    return enhance_image_2(image_array)\n",
    "  if i == 7:\n",
    "    return enhance_image_8(image_array)\n",
    "  if i == 8:\n",
    "    return enhance_image_9(image_array)\n",
    "\n",
    "# Function to enhance image by applying resizing, smoothing, sharpening, and contrast adjustments\n",
    "def enhance_image_1(image_array):\n",
    "    # Convert the NumPy array to a PIL Image for resizing\n",
    "    image = Image.fromarray(image_array)\n",
    "\n",
    "    # Convert to OpenCV format for applying smoothing\n",
    "    image_bgr = np.array(image)\n",
    "    image_bgr = cv2.cvtColor(image_bgr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Convert back to RGB and PIL Image for further processing\n",
    "    smoothed_image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(smoothed_image_rgb)\n",
    "\n",
    "    # Step 3: Apply Unsharp Masking for mild sharpening\n",
    "    unsharp_image_1 = image.filter(ImageFilter.UnsharpMask(radius=1, percent=110, threshold=3))\n",
    "\n",
    "    return unsharp_image_1\n",
    "\n",
    "def enhance_image_8(image_array):\n",
    "    # Convert the NumPy array to a PIL Image for resizing\n",
    "    image = Image.fromarray(image_array)\n",
    "\n",
    "    # Step 1: Resize the image to 224x224\n",
    "    #resized_image = image.resize((224, 224))\n",
    "\n",
    "    # Convert to OpenCV format for applying smoothing\n",
    "    image_bgr = np.array(image)\n",
    "    image_bgr = cv2.cvtColor(image_bgr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Step 2: Apply Gaussian Smoothing to reduce mosaic noise\n",
    "    smoothed_image = cv2.GaussianBlur(image_bgr, (3, 3), sigmaX=1)\n",
    "    denoised_image = cv2.bilateralFilter(smoothed_image, 3, 3,3)\n",
    "    # Convert back to RGB and PIL Image for further processing\n",
    "    smoothed_image_rgb = cv2.cvtColor(denoised_image, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(smoothed_image_rgb)\n",
    "\n",
    "    # Step 3: Apply Unsharp Masking for mild sharpening\n",
    "    unsharp_image = image.filter(ImageFilter.UnsharpMask(radius=0.9, percent=200, threshold=0))\n",
    "\n",
    "    # Step 4: Increase Contrast\n",
    "    contrast_enhancer_8 = ImageEnhance.Contrast(unsharp_image)\n",
    "    contrast_image_8 = contrast_enhancer_8.enhance(1.1)  # Adjust contrast factor as needed\n",
    "\n",
    "    return contrast_image_8\n",
    "\n",
    "def enhance_image_9(image_array):\n",
    "    # Convert the NumPy array to a PIL Image for resizing\n",
    "    image = Image.fromarray(image_array)\n",
    "\n",
    "    # Step 1: Resize the image to 224x224\n",
    "    #resized_image = image.resize((224, 224))\n",
    "\n",
    "    # Convert to OpenCV format for applying smoothing\n",
    "    image_bgr = np.array(image)\n",
    "    image_bgr = cv2.cvtColor(image_bgr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Step 2: Apply Gaussian Smoothing to reduce mosaic noise\n",
    "    smoothed_image = cv2.GaussianBlur(image_bgr, (3, 3), sigmaX=1)\n",
    "    denoised_image = cv2.bilateralFilter(smoothed_image, 2, 2,2)\n",
    "    # Convert back to RGB and PIL Image for further processing\n",
    "    smoothed_image_rgb = cv2.cvtColor(denoised_image, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(smoothed_image_rgb)\n",
    "\n",
    "    # Step 3: Apply Unsharp Masking for mild sharpening\n",
    "    unsharp_image = image.filter(ImageFilter.UnsharpMask(radius=1, percent=200, threshold=0))\n",
    "\n",
    "    # Step 4: Increase Contrast\n",
    "    contrast_enhancer_9 = ImageEnhance.Contrast(unsharp_image)\n",
    "    contrast_image_9 = contrast_enhancer_9.enhance(1.2)  # Adjust contrast factor as needed\n",
    "\n",
    "    return contrast_image_9\n",
    "\n",
    "def enhance_image_2(image_array):\n",
    "    # Convert the NumPy array to a PIL Image for resizing\n",
    "    image = Image.fromarray(image_array)\n",
    "\n",
    "    # Step 1: Resize the image to 224x224\n",
    "    #resized_image = image.resize((224, 224))\n",
    "\n",
    "    # Convert to OpenCV format for applying smoothing\n",
    "    image_bgr = np.array(image)\n",
    "    image_bgr = cv2.cvtColor(image_bgr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Step 2: Apply Gaussian Smoothing to reduce mosaic noise\n",
    "    smoothed_image = cv2.GaussianBlur(image_bgr, (3, 3), sigmaX=1)\n",
    "    denoised_image = cv2.bilateralFilter(smoothed_image, 5,5,5)\n",
    "    # Convert back to RGB and PIL Image for further processing\n",
    "    smoothed_image_rgb = cv2.cvtColor(denoised_image, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(smoothed_image_rgb)\n",
    "\n",
    "    # Step 3: Apply Unsharp Masking for mild sharpening\n",
    "    unsharp_image = image.filter(ImageFilter.UnsharpMask(radius=1, percent=120, threshold=0))\n",
    "\n",
    "    # Step 4: Increase Contrast\n",
    "    contrast_enhancer_2 = ImageEnhance.Contrast(unsharp_image)\n",
    "    contrast_image_2 = contrast_enhancer_2.enhance(1.2)  # Adjust contrast factor as needed\n",
    "\n",
    "    return contrast_image_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ts0HIeq66D1O"
   },
   "outputs": [],
   "source": [
    "## functon for means and varainces\n",
    "def calc_embeddings(data , flag):\n",
    "  dataArr = np.zeros((1,512))\n",
    "\n",
    "  feature_vectors = [[] for _ in range(10)]\n",
    "\n",
    "  features = []\n",
    "  def hook_fn(module, input, output):\n",
    "      features.append(output)\n",
    "\n",
    "  # Register the hook on the dropout layer\n",
    "  head_block = model.avgpool\n",
    "  hook = head_block.register_forward_hook(hook_fn)\n",
    "\n",
    "  # Define the transformations\n",
    "  transform = transforms.Compose([\n",
    "      transforms.ToPILImage(),\n",
    "      transforms.Resize((224, 224)),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.47889522, 0.47227842, 0.43047404], std=[0.24205776, 0.23828046, 0.25874835])\n",
    "  ])\n",
    "\n",
    "  # Iterate through the input arrays to perform inference and collect feature vectors\n",
    "  for i in range(data.shape[0]):\n",
    "      if flag in [0,1,8,7]:\n",
    "        tempData = enhance_image(np.array(data[i]), flag)\n",
    "      else:\n",
    "        tempData = data[i]\n",
    "\n",
    "      input_tensor = transform(np.array(tempData)).unsqueeze(0).to(device)  # Add batch dimension\n",
    "      features.clear()\n",
    "      with torch.no_grad():\n",
    "          output = model(input_tensor)  # Perform inference\n",
    "\n",
    "      # Get the dropout layer output and corresponding label\n",
    "      dropout_output = features[0].cpu().numpy()  # Convert to NumPy array\n",
    "      dropout_output = dropout_output.reshape(1, 512)\n",
    "      dataArr = np.append(dataArr, dropout_output, axis=0)\n",
    "\n",
    "      # Clear the features list for the next iteration\n",
    "      features.clear()\n",
    "\n",
    "  return  dataArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kJA2JludUcnN"
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "def save_and_compress_array(array, tar_filename, npy_filename):\n",
    "    array = array[1:, :]\n",
    "    print(array.shape)\n",
    "    # Save the NumPy array as a .npy file\n",
    "    np.save(npy_filename, array)\n",
    "\n",
    "    # Create a .tar.gz archive and add the .npy file\n",
    "    with tarfile.open(tar_filename, 'w:gz') as tar:\n",
    "        tar.add(npy_filename)\n",
    "\n",
    "    # Clean up the intermediate .npy file\n",
    "    os.remove(npy_filename)\n",
    "\n",
    "    print(f\"Array saved and compressed to {tar_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6ycxc9g6cD_",
    "outputId": "79a8017b-1d4c-4768-fbcb-f5a45c60bb53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 512)\n",
      "Array saved and compressed to trainDataTwo1.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to trainDataTwo2.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to trainDataTwo3.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to trainDataTwo4.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to trainDataTwo5.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to trainDataTwo6.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to trainDataTwo7.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to trainDataTwo8.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to trainDataTwo9.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to trainDataTwo10.tar.gz\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "  dataArr = calc_embeddings(all_train_data_2[i-1] , i-1)\n",
    "  save_and_compress_array(dataArr,f\"trainDataTwo{i}.tar.gz\",f\"trainDataTwo{i}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjObEzRZ87T-",
    "outputId": "265d2eba-7155-4516-e569-1daee3a484ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 512)\n",
      "Array saved and compressed to evalDataTwo1.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to evalDataTwo2.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to evalDataTwo3.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to evalDataTwo4.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to evalDataTwo5.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to evalDataTwo6.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to evalDataTwo7.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to evalDataTwo8.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to evalDataTwo9.tar.gz\n",
      "(2500, 512)\n",
      "Array saved and compressed to evalDataTwo10.tar.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1,11):\n",
    "  dataArr = calc_embeddings(all_eval_data_2[i-1] , i-1)\n",
    "  save_and_compress_array(dataArr,f\"evalDataTwo{i}.tar.gz\",f\"evalDataTwo{i}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s72NbAv4xF4L",
    "outputId": "83a55c78-c332-4e69-877b-359de04e3967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd' -> '/content/Data1Embd'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/eval1.tar.gz' -> '/content/Data1Embd/eval1.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/eval3.tar.gz' -> '/content/Data1Embd/eval3.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/eval2.tar.gz' -> '/content/Data1Embd/eval2.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/eval4.tar.gz' -> '/content/Data1Embd/eval4.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/eval10.tar.gz' -> '/content/Data1Embd/eval10.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/eval8.tar.gz' -> '/content/Data1Embd/eval8.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/eval5.tar.gz' -> '/content/Data1Embd/eval5.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/train5.tar.gz' -> '/content/Data1Embd/train5.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/eval6.tar.gz' -> '/content/Data1Embd/eval6.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/eval9.tar.gz' -> '/content/Data1Embd/eval9.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/train1.tar.gz' -> '/content/Data1Embd/train1.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/eval7.tar.gz' -> '/content/Data1Embd/eval7.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/train6.tar.gz' -> '/content/Data1Embd/train6.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/train2.tar.gz' -> '/content/Data1Embd/train2.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/train4.tar.gz' -> '/content/Data1Embd/train4.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/train10.tar.gz' -> '/content/Data1Embd/train10.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/train3.tar.gz' -> '/content/Data1Embd/train3.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/train8.tar.gz' -> '/content/Data1Embd/train8.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/train9.tar.gz' -> '/content/Data1Embd/train9.tar.gz'\n",
      "'/content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd/train7.tar.gz' -> '/content/Data1Embd/train7.tar.gz'\n"
     ]
    }
   ],
   "source": [
    "!cp -av /content/drive/MyDrive/ml_asg_2/ml-mini-project2/Data1Embd /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jG18DaU8OxhL",
    "outputId": "73344832-38a1-4494-8043-93ece01c99e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the archive: ['train1.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['train2.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['train3.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['train4.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['train5.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['train6.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['train7.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['train8.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['train9.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['train10.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['eval1.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['eval2.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['eval3.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['eval4.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['eval5.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['eval6.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['eval7.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['eval8.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['eval9.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['eval10.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "(10, 2500, 512)\n",
      "(10, 2500, 512)\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import numpy as np\n",
    "\n",
    "dataSet_1_allTrainEmbed = []\n",
    "dataSet_1_allEvalEmbed = []\n",
    "\n",
    "trainDataSetPaths = [\n",
    "    '/content/Data1Embd/train1.tar.gz',\n",
    "    '/content/Data1Embd/train2.tar.gz',\n",
    "    '/content/Data1Embd/train3.tar.gz',\n",
    "    '/content/Data1Embd/train4.tar.gz',\n",
    "    '/content/Data1Embd/train5.tar.gz',\n",
    "    '/content/Data1Embd/train6.tar.gz',\n",
    "    '/content/Data1Embd/train7.tar.gz',\n",
    "    '/content/Data1Embd/train8.tar.gz',\n",
    "    '/content/Data1Embd/train9.tar.gz',\n",
    "    '/content/Data1Embd/train10.tar.gz',\n",
    "]\n",
    "\n",
    "evalDataSetPaths = [\n",
    "    '/content/Data1Embd/eval1.tar.gz',\n",
    "    '/content/Data1Embd/eval2.tar.gz',\n",
    "    '/content/Data1Embd/eval3.tar.gz',\n",
    "    '/content/Data1Embd/eval4.tar.gz',\n",
    "    '/content/Data1Embd/eval5.tar.gz',\n",
    "    '/content/Data1Embd/eval6.tar.gz',\n",
    "    '/content/Data1Embd/eval7.tar.gz',\n",
    "    '/content/Data1Embd/eval8.tar.gz',\n",
    "    '/content/Data1Embd/eval9.tar.gz',\n",
    "    '/content/Data1Embd/eval10.tar.gz',\n",
    "]\n",
    "\n",
    "def loadEmbeddings(tar_gz_path,bigArray):\n",
    "\n",
    "  # Extract the .npy file\n",
    "  with tarfile.open(tar_gz_path, \"r:gz\") as tar:\n",
    "      # List all files in the tar.gz archive\n",
    "      tar_members = tar.getnames()\n",
    "      print(\"Files in the archive:\", tar_members)\n",
    "\n",
    "      # Find and extract the .npy file\n",
    "      for member in tar_members:\n",
    "          if member.endswith(\".npy\"):\n",
    "              npy_file_name = member\n",
    "              tar.extract(member, \"extracted_files\")  # Extract to a folder\n",
    "              break\n",
    "      else:\n",
    "          raise FileNotFoundError(\"No .npy file found in the archive.\")\n",
    "\n",
    "  # Path to the extracted .npy file\n",
    "  extracted_npy_path = f\"extracted_files/{npy_file_name}\"\n",
    "\n",
    "  # Load the .npy file\n",
    "  pynData = np.load(extracted_npy_path, allow_pickle=True)  # Set allow_pickle if needed\n",
    "\n",
    "  # Print the loaded data\n",
    "  print(\"Data from the .npy file:\")\n",
    "  print(pynData.shape)\n",
    "\n",
    "  bigArray.append(pynData);\n",
    "\n",
    "for path in trainDataSetPaths:\n",
    "  loadEmbeddings(path,dataSet_1_allTrainEmbed)\n",
    "\n",
    "for path in evalDataSetPaths:\n",
    "  loadEmbeddings(path,dataSet_1_allEvalEmbed)\n",
    "\n",
    "dataSet_1_allTrainEmbed = np.array(dataSet_1_allTrainEmbed)\n",
    "dataSet_1_allEvalEmbed = np.array(dataSet_1_allEvalEmbed)\n",
    "print(dataSet_1_allTrainEmbed.shape)\n",
    "print(dataSet_1_allEvalEmbed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQVTIbIHLn4b",
    "outputId": "ce96257b-9d81-4ed3-9d6e-7d2e55fb62d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the archive: ['trainDataTwo1.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['trainDataTwo2.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['trainDataTwo3.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['trainDataTwo4.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['trainDataTwo5.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['trainDataTwo6.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['trainDataTwo7.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['trainDataTwo8.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['trainDataTwo9.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['trainDataTwo10.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['evalDataTwo1.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['evalDataTwo2.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['evalDataTwo3.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['evalDataTwo4.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['evalDataTwo5.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['evalDataTwo6.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['evalDataTwo7.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['evalDataTwo8.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['evalDataTwo9.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "Files in the archive: ['evalDataTwo10.npy']\n",
      "Data from the .npy file:\n",
      "(2500, 512)\n",
      "(10, 2500, 512)\n",
      "(10, 2500, 512)\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import numpy as np\n",
    "\n",
    "dataSet_2_allTrainEmbed = []\n",
    "dataSet_2_allEvalEmbed = []\n",
    "\n",
    "trainDataSetPaths = [\n",
    "    '/content/trainDataTwo1.tar.gz',\n",
    "    '/content/trainDataTwo2.tar.gz',\n",
    "    '/content/trainDataTwo3.tar.gz',\n",
    "    '/content/trainDataTwo4.tar.gz',\n",
    "    '/content/trainDataTwo5.tar.gz',\n",
    "    '/content/trainDataTwo6.tar.gz',\n",
    "    '/content/trainDataTwo7.tar.gz',\n",
    "    '/content/trainDataTwo8.tar.gz',\n",
    "    '/content/trainDataTwo9.tar.gz',\n",
    "    '/content/trainDataTwo10.tar.gz',\n",
    "]\n",
    "\n",
    "evalDataSetPaths = [\n",
    "    '/content/evalDataTwo1.tar.gz',\n",
    "    '/content/evalDataTwo2.tar.gz',\n",
    "    '/content/evalDataTwo3.tar.gz',\n",
    "    '/content/evalDataTwo4.tar.gz',\n",
    "    '/content/evalDataTwo5.tar.gz',\n",
    "    '/content/evalDataTwo6.tar.gz',\n",
    "    '/content/evalDataTwo7.tar.gz',\n",
    "    '/content/evalDataTwo8.tar.gz',\n",
    "    '/content/evalDataTwo9.tar.gz',\n",
    "    '/content/evalDataTwo10.tar.gz',\n",
    "]\n",
    "\n",
    "def loadEmbeddings(tar_gz_path,bigArray):\n",
    "\n",
    "  # Extract the .npy file\n",
    "  with tarfile.open(tar_gz_path, \"r:gz\") as tar:\n",
    "      # List all files in the tar.gz archive\n",
    "      tar_members = tar.getnames()\n",
    "      print(\"Files in the archive:\", tar_members)\n",
    "\n",
    "      # Find and extract the .npy file\n",
    "      for member in tar_members:\n",
    "          if member.endswith(\".npy\"):\n",
    "              npy_file_name = member\n",
    "              tar.extract(member, \"extracted_files\")  # Extract to a folder\n",
    "              break\n",
    "      else:\n",
    "          raise FileNotFoundError(\"No .npy file found in the archive.\")\n",
    "\n",
    "  # Path to the extracted .npy file\n",
    "  extracted_npy_path = f\"extracted_files/{npy_file_name}\"\n",
    "\n",
    "  # Load the .npy file\n",
    "  pynData = np.load(extracted_npy_path, allow_pickle=True)  # Set allow_pickle if needed\n",
    "\n",
    "  # Print the loaded data\n",
    "  print(\"Data from the .npy file:\")\n",
    "  print(pynData.shape)\n",
    "\n",
    "  bigArray.append(pynData);\n",
    "\n",
    "for path in trainDataSetPaths:\n",
    "  loadEmbeddings(path,dataSet_2_allTrainEmbed)\n",
    "\n",
    "for path in evalDataSetPaths:\n",
    "  loadEmbeddings(path,dataSet_2_allEvalEmbed)\n",
    "\n",
    "dataSet_2_allTrainEmbed = np.array(dataSet_2_allTrainEmbed)\n",
    "dataSet_2_allEvalEmbed = np.array(dataSet_2_allEvalEmbed)\n",
    "print(dataSet_2_allTrainEmbed.shape)\n",
    "print(dataSet_2_allEvalEmbed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BFptpw8cNjJV"
   },
   "outputs": [],
   "source": [
    "def mean(dataSet11Emb , targets):\n",
    "  feature_vectors = [[] for _ in range(10)]\n",
    "  # Iterate through the input arrays to perform inference and collect feature vectors\n",
    "  for i in range(targets.shape[0]):\n",
    "      dropout_output = dataSet11Emb[i]\n",
    "      class_label = targets[i]\n",
    "\n",
    "      # Store the feature vector in the corresponding class list\n",
    "      feature_vectors[class_label].append(dropout_output)\n",
    "\n",
    "  # Calculate mean and variance for each class\n",
    "  mean = {}\n",
    "  for class_idx in range(10):\n",
    "      if feature_vectors[class_idx]:  # Check if there are feature vectors for this class\n",
    "          class_features = np.array(feature_vectors[class_idx])\n",
    "          mean_vector = np.mean(class_features, axis=0)\n",
    "          mean[class_idx] = (mean_vector)\n",
    "      else:\n",
    "          mean[class_idx] = (None, None)  # No samples for this class\n",
    "\n",
    "  # Print the results\n",
    "  '''\n",
    "  for class_idx in range(10):\n",
    "      mean, variance = mean_variance[class_idx]\n",
    "      print(f\"Class {class_idx}: Mean = {mean}, Variance = {variance}\")'''\n",
    "\n",
    "  # Remove the hook\n",
    "\n",
    "  prototypes = {}\n",
    "  for class_idx in range(10):\n",
    "      mean_vector= mean[class_idx]\n",
    "      prototypes[class_idx] = mean_vector\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  return prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bfo3qzXONn9-"
   },
   "outputs": [],
   "source": [
    "# function to calculate euclidean distance\n",
    "def distance_euc(x, mean):\n",
    "    diff = x - mean\n",
    "\n",
    "    return np.sqrt(diff @ diff.T)\n",
    "def classify_with_prototypes(feature_vector, prototypes):\n",
    "    distances = {}\n",
    "    for class_idx, prototype in prototypes.items():\n",
    "        if prototype is not None:  # Check if the prototype exists\n",
    "            distance = distance_euc(feature_vector, prototype)\n",
    "            distances[class_idx] = distance\n",
    "\n",
    "    # Return the class with the minimum distance\n",
    "    predicted_class = min(distances, key=distances.get)\n",
    "    return predicted_class\n",
    "\n",
    "def pred(i, j, prototypes ):\n",
    "  predicted_class = classify_with_prototypes(dataSet_1_allEvalEmbed[i][j], prototypes)\n",
    "  return predicted_class\n",
    "\n",
    "def pred2(i, j, prototypes):\n",
    "  predicted_class = classify_with_prototypes(dataSet_2_allTrainEmbed[i][j], prototypes)\n",
    "  return predicted_class\n",
    "\n",
    "def pred1(i, j, prototypes ):\n",
    "  predicted_class = classify_with_prototypes(dataSet_2_allEvalEmbed[i][j], prototypes)\n",
    "  return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uakMKWSqNqlI"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def evaluate(ind , prototypes1):\n",
    "  predict=[]\n",
    "  print(f\"Evaluation metrics for model {ind+1}\")\n",
    "  for i in range(11+ind):\n",
    "    for j in range(2500):\n",
    "      if i<10:\n",
    "        predict.append(pred(i ,j , prototypes1))\n",
    "      else:\n",
    "        predict.append(pred1(i%10 ,j , prototypes1))\n",
    "    if i<10:\n",
    "      accuracy = accuracy_score(all_eval_targets[i], predict)\n",
    "    else:\n",
    "      accuracy = accuracy_score(all_eval_targets_2[i%10], predict)\n",
    "    # Print the metrics\n",
    "    if i<10:\n",
    "      print(f\"Set 1 for Dataset {i+1} Accuracy : {accuracy:.4f}\")\n",
    "    else:\n",
    "      print(f\"Set 2 for Dataset {(i+1)%10} Accuracy : {accuracy:.4f}\")\n",
    "    predict=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ipc8t-88xr6y",
    "outputId": "2a77c369-87da-45fa-f9fc-2877814aef6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from the .pkl file:\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "mean_path = '/content/drive/MyDrive/ml_asg_2/ml-mini-project2/mean_after_1.1.pkl'\n",
    "\n",
    "# Load the .pkl file\n",
    "with open(mean_path, \"rb\") as file:  # 'rb' means read in binary mode\n",
    "    mean_new = pickle.load(file)\n",
    "\n",
    "# Print the loaded data\n",
    "print(\"Data from the .pkl file:\")\n",
    "#print(mean_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "40ZIegFmNscl"
   },
   "outputs": [],
   "source": [
    "prototypes1 = mean_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLeR1ZIYNt5b",
    "outputId": "c8791ece-9eb1-453a-ee6d-b7d3e3a09e0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics for model 1\n",
      "Set 1 for Dataset 1 Accuracy : 0.9564\n",
      "Set 1 for Dataset 2 Accuracy : 0.9492\n",
      "Set 1 for Dataset 3 Accuracy : 0.9508\n",
      "Set 1 for Dataset 4 Accuracy : 0.9464\n",
      "Set 1 for Dataset 5 Accuracy : 0.9548\n",
      "Set 1 for Dataset 6 Accuracy : 0.9460\n",
      "Set 1 for Dataset 7 Accuracy : 0.9468\n",
      "Set 1 for Dataset 8 Accuracy : 0.9496\n",
      "Set 1 for Dataset 9 Accuracy : 0.9476\n",
      "Set 1 for Dataset 10 Accuracy : 0.9536\n",
      "Set 2 for Dataset 1 Accuracy : 0.8268\n",
      "Evaluation metrics for model 2\n",
      "Set 1 for Dataset 1 Accuracy : 0.9564\n",
      "Set 1 for Dataset 2 Accuracy : 0.9492\n",
      "Set 1 for Dataset 3 Accuracy : 0.9512\n",
      "Set 1 for Dataset 4 Accuracy : 0.9480\n",
      "Set 1 for Dataset 5 Accuracy : 0.9536\n",
      "Set 1 for Dataset 6 Accuracy : 0.9460\n",
      "Set 1 for Dataset 7 Accuracy : 0.9468\n",
      "Set 1 for Dataset 8 Accuracy : 0.9484\n",
      "Set 1 for Dataset 9 Accuracy : 0.9472\n",
      "Set 1 for Dataset 10 Accuracy : 0.9540\n",
      "Set 2 for Dataset 1 Accuracy : 0.8292\n",
      "Set 2 for Dataset 2 Accuracy : 0.6384\n",
      "Evaluation metrics for model 3\n",
      "Set 1 for Dataset 1 Accuracy : 0.9576\n",
      "Set 1 for Dataset 2 Accuracy : 0.9496\n",
      "Set 1 for Dataset 3 Accuracy : 0.9516\n",
      "Set 1 for Dataset 4 Accuracy : 0.9472\n",
      "Set 1 for Dataset 5 Accuracy : 0.9524\n",
      "Set 1 for Dataset 6 Accuracy : 0.9452\n",
      "Set 1 for Dataset 7 Accuracy : 0.9464\n",
      "Set 1 for Dataset 8 Accuracy : 0.9488\n",
      "Set 1 for Dataset 9 Accuracy : 0.9464\n",
      "Set 1 for Dataset 10 Accuracy : 0.9536\n",
      "Set 2 for Dataset 1 Accuracy : 0.8264\n",
      "Set 2 for Dataset 2 Accuracy : 0.6360\n",
      "Set 2 for Dataset 3 Accuracy : 0.8036\n",
      "Evaluation metrics for model 4\n",
      "Set 1 for Dataset 1 Accuracy : 0.9576\n",
      "Set 1 for Dataset 2 Accuracy : 0.9492\n",
      "Set 1 for Dataset 3 Accuracy : 0.9508\n",
      "Set 1 for Dataset 4 Accuracy : 0.9468\n",
      "Set 1 for Dataset 5 Accuracy : 0.9524\n",
      "Set 1 for Dataset 6 Accuracy : 0.9456\n",
      "Set 1 for Dataset 7 Accuracy : 0.9468\n",
      "Set 1 for Dataset 8 Accuracy : 0.9484\n",
      "Set 1 for Dataset 9 Accuracy : 0.9460\n",
      "Set 1 for Dataset 10 Accuracy : 0.9536\n",
      "Set 2 for Dataset 1 Accuracy : 0.8260\n",
      "Set 2 for Dataset 2 Accuracy : 0.6340\n",
      "Set 2 for Dataset 3 Accuracy : 0.8032\n",
      "Set 2 for Dataset 4 Accuracy : 0.8756\n",
      "Evaluation metrics for model 5\n",
      "Set 1 for Dataset 1 Accuracy : 0.9568\n",
      "Set 1 for Dataset 2 Accuracy : 0.9476\n",
      "Set 1 for Dataset 3 Accuracy : 0.9504\n",
      "Set 1 for Dataset 4 Accuracy : 0.9468\n",
      "Set 1 for Dataset 5 Accuracy : 0.9524\n",
      "Set 1 for Dataset 6 Accuracy : 0.9448\n",
      "Set 1 for Dataset 7 Accuracy : 0.9468\n",
      "Set 1 for Dataset 8 Accuracy : 0.9484\n",
      "Set 1 for Dataset 9 Accuracy : 0.9460\n",
      "Set 1 for Dataset 10 Accuracy : 0.9532\n",
      "Set 2 for Dataset 1 Accuracy : 0.8244\n",
      "Set 2 for Dataset 2 Accuracy : 0.6316\n",
      "Set 2 for Dataset 3 Accuracy : 0.8016\n",
      "Set 2 for Dataset 4 Accuracy : 0.8752\n",
      "Set 2 for Dataset 5 Accuracy : 0.9168\n",
      "Evaluation metrics for model 6\n",
      "Set 1 for Dataset 1 Accuracy : 0.9572\n",
      "Set 1 for Dataset 2 Accuracy : 0.9488\n",
      "Set 1 for Dataset 3 Accuracy : 0.9500\n",
      "Set 1 for Dataset 4 Accuracy : 0.9472\n",
      "Set 1 for Dataset 5 Accuracy : 0.9520\n",
      "Set 1 for Dataset 6 Accuracy : 0.9448\n",
      "Set 1 for Dataset 7 Accuracy : 0.9472\n",
      "Set 1 for Dataset 8 Accuracy : 0.9484\n",
      "Set 1 for Dataset 9 Accuracy : 0.9448\n",
      "Set 1 for Dataset 10 Accuracy : 0.9544\n",
      "Set 2 for Dataset 1 Accuracy : 0.8236\n",
      "Set 2 for Dataset 2 Accuracy : 0.6268\n",
      "Set 2 for Dataset 3 Accuracy : 0.8024\n",
      "Set 2 for Dataset 4 Accuracy : 0.8756\n",
      "Set 2 for Dataset 5 Accuracy : 0.9172\n",
      "Set 2 for Dataset 6 Accuracy : 0.7652\n",
      "Evaluation metrics for model 7\n",
      "Set 1 for Dataset 1 Accuracy : 0.9572\n",
      "Set 1 for Dataset 2 Accuracy : 0.9488\n",
      "Set 1 for Dataset 3 Accuracy : 0.9500\n",
      "Set 1 for Dataset 4 Accuracy : 0.9464\n",
      "Set 1 for Dataset 5 Accuracy : 0.9524\n",
      "Set 1 for Dataset 6 Accuracy : 0.9448\n",
      "Set 1 for Dataset 7 Accuracy : 0.9472\n",
      "Set 1 for Dataset 8 Accuracy : 0.9476\n",
      "Set 1 for Dataset 9 Accuracy : 0.9444\n",
      "Set 1 for Dataset 10 Accuracy : 0.9536\n",
      "Set 2 for Dataset 1 Accuracy : 0.8244\n",
      "Set 2 for Dataset 2 Accuracy : 0.6264\n",
      "Set 2 for Dataset 3 Accuracy : 0.8016\n",
      "Set 2 for Dataset 4 Accuracy : 0.8752\n",
      "Set 2 for Dataset 5 Accuracy : 0.9168\n",
      "Set 2 for Dataset 6 Accuracy : 0.7660\n",
      "Set 2 for Dataset 7 Accuracy : 0.8860\n",
      "Evaluation metrics for model 8\n",
      "Set 1 for Dataset 1 Accuracy : 0.9576\n",
      "Set 1 for Dataset 2 Accuracy : 0.9480\n",
      "Set 1 for Dataset 3 Accuracy : 0.9508\n",
      "Set 1 for Dataset 4 Accuracy : 0.9472\n",
      "Set 1 for Dataset 5 Accuracy : 0.9516\n",
      "Set 1 for Dataset 6 Accuracy : 0.9460\n",
      "Set 1 for Dataset 7 Accuracy : 0.9464\n",
      "Set 1 for Dataset 8 Accuracy : 0.9484\n",
      "Set 1 for Dataset 9 Accuracy : 0.9448\n",
      "Set 1 for Dataset 10 Accuracy : 0.9528\n",
      "Set 2 for Dataset 1 Accuracy : 0.8232\n",
      "Set 2 for Dataset 2 Accuracy : 0.6276\n",
      "Set 2 for Dataset 3 Accuracy : 0.8016\n",
      "Set 2 for Dataset 4 Accuracy : 0.8760\n",
      "Set 2 for Dataset 5 Accuracy : 0.9164\n",
      "Set 2 for Dataset 6 Accuracy : 0.7656\n",
      "Set 2 for Dataset 7 Accuracy : 0.8852\n",
      "Set 2 for Dataset 8 Accuracy : 0.7428\n",
      "Evaluation metrics for model 9\n",
      "Set 1 for Dataset 1 Accuracy : 0.9572\n",
      "Set 1 for Dataset 2 Accuracy : 0.9480\n",
      "Set 1 for Dataset 3 Accuracy : 0.9492\n",
      "Set 1 for Dataset 4 Accuracy : 0.9464\n",
      "Set 1 for Dataset 5 Accuracy : 0.9512\n",
      "Set 1 for Dataset 6 Accuracy : 0.9456\n",
      "Set 1 for Dataset 7 Accuracy : 0.9456\n",
      "Set 1 for Dataset 8 Accuracy : 0.9480\n",
      "Set 1 for Dataset 9 Accuracy : 0.9444\n",
      "Set 1 for Dataset 10 Accuracy : 0.9524\n",
      "Set 2 for Dataset 1 Accuracy : 0.8244\n",
      "Set 2 for Dataset 2 Accuracy : 0.6296\n",
      "Set 2 for Dataset 3 Accuracy : 0.8004\n",
      "Set 2 for Dataset 4 Accuracy : 0.8760\n",
      "Set 2 for Dataset 5 Accuracy : 0.9168\n",
      "Set 2 for Dataset 6 Accuracy : 0.7640\n",
      "Set 2 for Dataset 7 Accuracy : 0.8852\n",
      "Set 2 for Dataset 8 Accuracy : 0.7428\n",
      "Set 2 for Dataset 9 Accuracy : 0.7688\n",
      "Evaluation metrics for model 10\n",
      "Set 1 for Dataset 1 Accuracy : 0.9556\n",
      "Set 1 for Dataset 2 Accuracy : 0.9480\n",
      "Set 1 for Dataset 3 Accuracy : 0.9492\n",
      "Set 1 for Dataset 4 Accuracy : 0.9472\n",
      "Set 1 for Dataset 5 Accuracy : 0.9512\n",
      "Set 1 for Dataset 6 Accuracy : 0.9448\n",
      "Set 1 for Dataset 7 Accuracy : 0.9456\n",
      "Set 1 for Dataset 8 Accuracy : 0.9480\n",
      "Set 1 for Dataset 9 Accuracy : 0.9440\n",
      "Set 1 for Dataset 10 Accuracy : 0.9524\n",
      "Set 2 for Dataset 1 Accuracy : 0.8252\n",
      "Set 2 for Dataset 2 Accuracy : 0.6300\n",
      "Set 2 for Dataset 3 Accuracy : 0.8004\n",
      "Set 2 for Dataset 4 Accuracy : 0.8756\n",
      "Set 2 for Dataset 5 Accuracy : 0.9168\n",
      "Set 2 for Dataset 6 Accuracy : 0.7644\n",
      "Set 2 for Dataset 7 Accuracy : 0.8856\n",
      "Set 2 for Dataset 8 Accuracy : 0.7412\n",
      "Set 2 for Dataset 9 Accuracy : 0.7684\n",
      "Set 2 for Dataset 0 Accuracy : 0.8668\n"
     ]
    }
   ],
   "source": [
    "prototypes = prototypes1.copy()\n",
    "for i in range(10):\n",
    "  predict_target = []\n",
    "  for j in range(2500):\n",
    "    predict_target.append(pred2(i , j , prototypes))\n",
    "  predict_target = np.array(predict_target)\n",
    "  new_mean = mean(dataSet_2_allTrainEmbed[i]  , predict_target)\n",
    "  for k in range(10):\n",
    "    prototypes[k] = (0.9 * prototypes[k] + 0.1 * new_mean[k])\n",
    "  evaluate(i, prototypes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zwA2NkqtNv0I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
